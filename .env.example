# ============================================================================
# COMMON SETTINGS
# ============================================================================
NODE_ENV=development

# ============================================================================
# POSTGRES DATABASE
# ============================================================================
POSTGRES_DB=corely
POSTGRES_USER=corely
POSTGRES_PASSWORD=corely
DATABASE_URL=postgresql://corely:corely@postgres:5432/corely?schema=public

# ============================================================================
# REDIS CACHE & QUEUE
# ============================================================================
REDIS_URL=redis://redis:6379
# Queue driver: bullmq | memory | cloudtasks
WORKFLOW_QUEUE_DRIVER=bullmq
# Optional shared secret for Cloud Tasks HTTP delivery
WORKFLOW_QUEUE_SECRET=

# Cloud Tasks (used when WORKFLOW_QUEUE_DRIVER=cloudtasks)
WORKFLOW_CLOUDTASKS_LOCATION=
WORKFLOW_CLOUDTASKS_QUEUE_PREFIX=
WORKFLOW_CLOUDTASKS_TARGET_BASE_URL=
WORKFLOW_CLOUDTASKS_SERVICE_ACCOUNT=

# ============================================================================
# FRONTEND (VITE)
# ============================================================================
# For DEMO profile (uses mock-server):
# VITE_API_BASE_URL=http://localhost:4000
# For FULL profile (uses real API):
# VITE_API_BASE_URL=http://localhost:3000

# Default to real API; set VITE_API_MODE=mock to point to mock server
VITE_API_BASE_URL=http://localhost:3000
VITE_API_MODE=real

# ============================================================================
# PORTS
# ============================================================================
WEB_PORT=5173
API_PORT=3000
MOCK_PORT=4000
WORKER_PORT=3001

# ============================================================================
# LOGGING
# ============================================================================
LOG_LEVEL=debug

# ============================================================================
# AI PROVIDERS
# ============================================================================
# Set provider: openai | anthropic
AI_MODEL_PROVIDER=anthropic
# Default model IDs (override per env if needed)
AI_MODEL_ID=gpt-4o-mini
# OpenAI API key
OPENAI_API_KEY=
# Anthropic API key
ANTHROPIC_API_KEY=
# Example Anthropic setup:
# AI_MODEL_PROVIDER=anthropic
# AI_MODEL_ID=claude-3-5-sonnet-20240620
# ANTHROPIC_API_KEY=sk-ant-...

# ============================================================================
# EMAIL PROVIDERS
# ============================================================================
# Select provider: resend | sendgrid | ses | postmark (only resend implemented)
EMAIL_PROVIDER=resend
RESEND_API_KEY=
RESEND_FROM="Corely Billing <billing@example.com>"
RESEND_REPLY_TO=
RESEND_WEBHOOK_SECRET=

# ============================================================================
# OBJECT STORAGE (GCS default)
# ============================================================================
STORAGE_PROVIDER=gcs
STORAGE_BUCKET=uploads
STORAGE_KEY_PREFIX=env/dev
SIGNED_URL_UPLOAD_TTL_SECONDS=600
SIGNED_URL_DOWNLOAD_TTL_SECONDS=600
MAX_UPLOAD_BYTES=52428800
# Optional Google credentials
GOOGLE_CLOUD_PROJECT=
GOOGLE_APPLICATION_CREDENTIALS=

# ============================================================================
# OBSERVABILITY (Langfuse/OTLP)
# ============================================================================
# Options: none | otel | langfuse
OBSERVABILITY_PROVIDER=none
# Sampling ratio 0-1 (use 1 for dev/staging)
OBSERVABILITY_SAMPLE_RATIO=1
# Masking: off | standard | strict
OBSERVABILITY_MASKING_MODE=standard
# OTLP endpoint (Langfuse Cloud: https://cloud.langfuse.com/otlp)
OTEL_EXPORTER_OTLP_ENDPOINT=
# Optional extra headers (key=value comma-separated) if not using Langfuse basic auth
OTEL_EXPORTER_OTLP_HEADERS=
# Langfuse auth (used when provider=langfuse)
LANGFUSE_BASE_URL=
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
